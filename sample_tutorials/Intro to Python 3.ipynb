{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Intro to Python 3: Dictionaries and Dataframes"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "While organizing data into tuples and lists is fine for our use, Python provides several more sophisticated ways of labeling and archiving data. In this tutorial, we will cover other ways of storing data: **dictionaries** and **dataframes**.\n\nAdditionally, this tutorial will cover how to import and run **packages** in Python, as well as provide a brief primer into using **Regular Expressions**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Dictionaries\n\nPython's dictionaries are similar to tuples and lists when it comes to data structures. **Dictionaries** are structured by a combination of **keys** and **values**. Dictionaries are commonly used for counting tokens in a text document, but there are several other applications.\n\nBut why use a dictionary over a series of nested lists or tuples? Dictionaries come with a large number of indexing commands. These commands are especially helpful when you're only concerned about a string have one possible value. This is to say that if you're concerned about the vectors and matrices that constitute the word \"the\" in a text document, dictionaries are a bad bet.\n\nBelow, I'll create a dictionary using squiggly brackets."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#dict#\nflavors = {\"blueberry\": 2.99, \"cosmic key lime\": 3.39, \"orange\": 3.29, \"wild berry\": 2.00}\n",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Apart from the less inspiring names, this flavors dictionary should look eerily similar to lists from previous execises. If you'll recall, we needed to use the **min** and **max** function in conjunction with lambda to find out the most expensive flavor. Below we'll compare how similar finding the cheapest toaster pastry flavor is when using a dictionary entry or a nested tuple."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#nested_tuples#\nflavors_l = [(\"blueberry\", 2.99), (\"cosmic key lime\", 3.39), (\"orange\", 3.29), (\"wild berry\", 2.00)]",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#using dict#\nmin(flavors.keys(), key=(lambda k: flavors[k]))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "'wild berry'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#using tuple#\nmin(flavors_l, key = lambda entry: entry[1])[0]\n",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'wild berry'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "A few differences are worth noting. Rather than using brackets to determine which subsection of flavors_1 we're refering to with tuples (entry[1]), dictionary entires are pairs of keys and values. Additionally, sincle the min function returns the tuple in flavors_1, we need to add the [0] at the end of the command to return \"wild berry.\"\n\nWhile these differences may seem negligible, a dictionary's strengths really shine when we know the keyword we would like a value for. Compare the two processes below for finding out how much a blueberry toaster pastry costs."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#using dict@\nflavors[\"blueberry\"]",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "2.99"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#using tuples#\nfor entry in flavors_l:\n    if \"blueberry\" in entry[0]:\n        print(entry[1])\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "2.99\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Dictionaries are slightly more intuitive to use when we know the keyterm we want information on. If \"blueberry\" were the last tuple in a very large list, it would take longer to loop through that list instead of using a dictionary's key/value pair. Indeed, it's important to imagine applications where you're dealing with thousands of words that are featured multiple times; looping would be a bit like finding a needle in a haystack straw by straw. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Regular Expressions\n\n**Regular Expressions** are patterns used find specific strings of text within large strings. For instance, imagine you were presented with data in the following way: \"blueberry toaster pastries sell for two dollars and ninety-nine cents,\" \"orange toaster pastries sell for three dollars and twenty-nine cents\", \"ice cream sundae toaster pastries sell for four dollars.\" If your job was to turn this data into a dictionary that listed flavor and price, you would need to identify and convert textual patterns.\n\nLet's start with flavor. Looking at the data below, we can tell that words that appear before the string \"toaster\" typically contain flavor information. The first thing we want to do is to break these strings into individual tokens. To do this, we're going to first import the re package in Python and then create a word patter.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "textual_data = [\"Blueberry toaster pastries sell for two dollars and ninety-nine cents.\", \"Orange toaster pastries sell for three dollars and twenty-nine cents.\", \"Ice cream sundae toaster pastries sell for four dollars.\"]",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\n\nword_pattern = re.compile(\"\\w[\\w\\-\\']*\\w\")",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Re is the package used for regular expressions. In Python, you can import packages using the command **import**. If you only needed a specific part of a package, you can clarify **from re import re.compile**.\n\nPackages are a series of predefined functions that are not available in the basic version of Python. It is often preferable to use the same packages as others rather than write redundant functions; online support communities, optimization, and ease of use should not be taken for granted!\n\nNow that we've imported re, we might ask what this word_pattern means? \\w means any word character. In brackets, we clarify that we're including \\w to also mean that once character can be a hypen or an apostrophe. The * implies that the pattern will continue until it reaches a character that is not a word character. https://regex101.com provides a helpful interface for learning more about and testing different RegEx patterns.\n\nFor this instance, word_pattern is similar to the **split()** command used earlier in that it will allow us to turn sentences into tokens. There is, however, a notable difference."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#with regex#\nfor line in textual_data:\n    print(word_pattern.findall(line))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['Blueberry', 'toaster', 'pastries', 'sell', 'for', 'two', 'dollars', 'and', 'ninety-nine', 'cents']\n['Orange', 'toaster', 'pastries', 'sell', 'for', 'three', 'dollars', 'and', 'twenty-nine', 'cents']\n['Ice', 'cream', 'sundae', 'toaster', 'pastries', 'sell', 'for', 'four', 'dollars']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#with split#\nfor line in textual_data:\n    print(line.split())",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['Blueberry', 'toaster', 'pastries', 'sell', 'for', 'two', 'dollars', 'and', 'ninety-nine', 'cents.']\n['Orange', 'toaster', 'pastries', 'sell', 'for', 'three', 'dollars', 'and', 'twenty-nine', 'cents.']\n['Ice', 'cream', 'sundae', 'toaster', 'pastries', 'sell', 'for', 'four', 'dollars.']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "If you look at \"cents\", you'll see the split() method retained punctation. In sentences that feature far more punctuation, this can compromise our ability to match words [\"cents\" does not equal \"cents.\"] \n\nWe can expand our regex method from above to extract flavor information."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in textual_data:\n    flavors = []\n    line_w_tokens = word_pattern.findall(line)\n    for token in line_w_tokens:\n        if token != \"toaster\":\n            flavors.append(token)\n        else:\n            break\n    print(\" \".join(flavors).lower())",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "blueberry\norange\nice cream sundae\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "raw",
      "source": "The code above loops to collect all tokens before the token \"toaster\". Once \"toaster' appears, the for-loop breaks. The **join** command takes all of the list and turns them into a single string. This is important so that we get \"ice cream sundae\" instead of [\"ice\", \"cream\", \"sundae\"]\n\nNext, we'll want to come up with a rule to turn the strings that represent the price of the toaster pastries into a float. Doing this means that the dollar amount is the string before the word \"dollars\" and the cents amount is the string before the word \"cents.\" Since we have one string attached to one value, this is an excellent opportunity to use a dictionary. Below, I've written the unique numbers between one and ninety-nine using a dictionary."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "string2num_dict = {\"zero\":0, \"one\":1, \"two\":2, \"three\":3, \"four\":4,\"five\":5,\"six\":6,\"seven\":7,\"eight\":8, \"nine\":9, \"ten\":10, \"eleven\":11,\n                  \"twelve\":12, \"thirteen\":13, \"fourteen\":14, \"fifteen\":15, \"sixteen\":16, \"seventeen\":17, \"eighteen\":18, \"nineteen\":19,\n                  \"twenty\":20,\"thirty\":30, \"forty\":40, \"fifty\":50, \"sixty\":60,\"seventy\":70, \"eighty\": 80, \"ninety\":90}",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def dollars_and_cents(token):\n    if \"-\" in token:\n        separated = token.split(\"-\")\n        tens = string2num_dict[separated[0]]\n        return(tens + string2num_dict[separated[1]])\n    else:\n        return(string2num_dict[token])",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#test#\ndollars_and_cents(\"twenty-one\")",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "21"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the function above, words that have a hypen in them are split. Since the dictionary would be very long if we included entries like {\"twenty-one\":21}, splitting the word in two allows us to be more efficient. Once both parts of the string have been given numerical values, the two are added back together. If we include this function in the for-loop from earlier, we should be able to get all of the data we need."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def itemizer(line):\n    line_w_tokens = word_pattern.findall(line)\n    cost = 0\n    for position in range(len(line_w_tokens)):\n        if line_w_tokens[position] == \"toaster\":\n            flavor = \" \".join(line_w_tokens[:position])\n        elif line_w_tokens[position] == \"dollars\":\n            dol_amt = dollars_and_cents(line_w_tokens[position -1])\n            cost += float(dol_amt)\n        elif line_w_tokens[position] == \"cents\":\n            cen_amt = dollars_and_cents(line_w_tokens[position -1])\n            cost += cen_amt/100\n        else:\n            pass\n    print((flavor.lower(), cost))",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in textual_data:\n    itemizer(line)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "('blueberry', 2.99)\n('orange', 3.29)\n('ice cream sundae', 4.0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## Dataframes\n\nImagine that you work for a coffee shop and receive the following e-mails from a boss:\n\n\"A new shipment of blueberry toaster pastries will be arriving on Friday. Each shipment contains twelve packages. We currently have four packages in stock.\"\n\n\"The orange toaster pastries will be here by Thursday. We currently have six packages in stock.\"\n\n\"I cancelled the shipment for ice cream sundae toaster pastries because they have not sold very well. We still have twelve in stock. On Thursday, we will reduce their price from four dollars to three dollars.\"\n\nUsing a dictionary to store this data would not make much sense; there are now many numbers to keep track of for each toaster pastry. While using a series of tuples might make sense, they lack the legibility that would make them helpful for another employee who was also hoping to keep track of inventories.\n\nLet's begin, however, by modifying our existing code to see how much information we can glean from these strings."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "shipment_data = []\n\ne_mails = [\"A new shipment of blueberry toaster pastries will be arriving on Friday. Each shipment contains twelve packages. We currently have four packages in stock.\",\n          \"The orange toaster pastries will be here by Thursday. We ordered two shipments containing six packages each. We currently have six packages in stock.\", \n           \"I cancelled the shipment for ice cream sundae toaster pastries because they have not sold very well. We still have twelve packages in stock.\"]\n",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in e_mails:\n    itemizer(line)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "('new shipment of blueberry', 0)\n('the orange', 0)\n('cancelled the shipment for ice cream sundae', 0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So using the existing code as is, we were able to still get some data about the relevant flavors. Still, this hasn't gotten us half the data that we want. Ideally, our code will tell us the following:\n1.) What flavor? 2.) How many are in stock? 3.) When does/Will a new shipment arrive? 4.) How many will be in stock after the shipment? \n\nIf we think of these questions as a spreadsheet, we would want five columns:\nflavor, stock, shipment, stock_after_shipment, price\n\nBefore we build a function, we should identify the tokens in the strings above that are important in relation to these questions.\n\n1.) Flavor occurs before the word **toaster** and after a preposition or an article.\n2.) The token before **packages in stock**\n3.) The token will be a day of the week. We can probably make a dictionary for this.\n4.) **shipment** or **shipments** + **contain** or **containing** We then need to add this to existing stock.\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#for toaster#\n#common preps from\ncommon_prepositions_and_articles = [\"of\", \"in\", \"to\", \"for\", \"with\",\n                                    \"on\",\"at\",\"from\",\"by\",\"about\",\"as\",\n                                   \"into\", \"like\",\"through\",\"after\", \"over\",\n                                   \"between\", \"out\", \"against\", \"during\",\"without\",\n                                   \"before\", \"under\",\"around\", \"among\", \"a\",\n                                   \"an\", \"the\"]\ndef find_flavor(line):\n    line_w_tokens = word_pattern.findall(line)\n    flavors = []\n    start = 0\n    for token in range(len(line_w_tokens)):\n        if line_w_tokens[token] != \"toaster\":\n            flavors.append(token)\n        else:\n            break       \n    for entry in reversed(flavors):\n        if line_w_tokens[entry].lower() in common_prepositions_and_articles:\n            start = entry + 1\n            break\n    return(\" \".join(line_w_tokens[start:len(flavors)]))",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in e_mails:\n    find_flavor(line)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The code above modifies our original function to find flavors quite significantly. The largest addition is the list of common prepositions and articles. While the earlier sentences had the names of the flavors at their beginning, letting us say that the flavor was equal to everything until the token \"toaster\", these sentences all begin differently: *A new shipment of blueberry*, *The orange*, and *I cancelled the shipment for ice cream sundae*. By adding a list of articles and prepositions, we are able to say where flavor description ends. *A new shipment **of** blueberry*, ***The** orange*, and *I cancelled the shipment **for** ice cream sundae*.\n\nIf you think of this as a sheet of paper we need to cut twice, our first direction tells our hands with scissors (or scissorhands) to move from left to right along the sheet until we come to the token toaster. This is how **iteration** typically works. Once we've made that cut the **reversed** function allows us to move right to left until we come to a preposition or article. Once we know where that point is, we are able to, in our final command, say that we only want the tokens between those two incisions."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#for in_stock#\ndef find_in_stock(line):\n    line_w_tokens = word_pattern.findall(line)\n    for position in range(len(line_w_tokens)):\n        if line_w_tokens[position] == \"stock\":\n            return(string2num_dict[line_w_tokens[position-3]])",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in e_mails:\n    find_in_stock(line)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This code is much more simple than that last! It looks for the token \"stock\" and then chooses the token that's three positions before that (skipping \"packages\" and \"in\"). It then uses that token position and turns it into a numeral using the dictionary from earlier.\n\nWhile this code works for this example, what issues could you see it running into if our dataset was larger and more varied than three sentences? What are the drawbacks of designing code around specific rules and keywords?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#for day_of_week#\nd_o_w = {\"Monday\":1, \"Tuesday\":2, \"Wednesday\":3, \"Thursday\":4, \"Friday\":5, \"Saturday\":6, \"Sunday\":7}\n\ndef find_dow (line):\n    line_w_tokens = word_pattern.findall(line)\n    dow = 0\n    for key in d_o_w:\n        if key in line_w_tokens:\n            dow += d_o_w[key]\n        else:\n            pass\n    return(dow)",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in e_mails:\n    find_dow(line)",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This code uses a dictionary to search the tokens for days of the week. Rather than return the matching day of the week, this code has the dictionary value added to a variable called dow. The reason for this is that we know one of the sentences involves a cancellation. Rather than returning no date, it's better to insert a 0; Python is sometimes finnicky about blank entries or None types."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#for stock#",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def find_amt (line):\n    line_w_tokens = word_pattern.findall(line)\n    multiplier = 1\n    quantity = 0\n    for position in range(len(line_w_tokens)):\n        if line_w_tokens[position] == \"shipments\":\n            no_shipments = string2num_dict[line_w_tokens[position-1]]\n            multiplier *= no_shipments\n        if \"shipment\" in line_w_tokens[position]:\n            if \"contain\" in line_w_tokens[position + 1]:\n                quantity += string2num_dict[line_w_tokens[position + 2]]\n    return(quantity * multiplier)\n ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for line in e_mails:\n    find_amt(line)",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This last big of code is probably the most complex so far. The multiplier and quantity variables allow us to determine what the final amount will be. When the word \"shipments\" appears, we can assume that the multiplier will be necessary. If we see the word \"shipment\" followed by \"contain\" (which can be contains or containing), we have reason to believe that the next word will be the quantity per shipment. The code ends with the quantity being multiplied by the multiplier.\n\nNow that we have these functions together, we can start assembling our data. A good intermediate step might be to see if there's any redundancy in the code we can make universal. For instance, the first line of each of our functions uses a Regular Expression to break the sentence down into tokens. Rather than do that four times, it would make more sense to do it once. One of the exercises below will ask you to do this.\n\nFor now, let's turn our sentences into tuples!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "inventory_data = []\n\nfor line in e_mails:\n    inventory_data.append((find_flavor(line), find_in_stock(line), find_dow(line), find_amt(line)))",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "inventory_data",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "[('blueberry', 4, 5, 12), ('orange', 6, 4, 12), ('ice cream sundae', 12, 0, 0)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So beautiful, and yet the presentation leaves so much to be desired. Using Pandas, we're going to turn this into a dataframe."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ndataframe = pd.DataFrame(inventory_data, columns = [\"flavor\", \"stock\", \"shipment\", \"quantity in shipment\"])",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataframe",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flavor</th>\n      <th>stock</th>\n      <th>shipment</th>\n      <th>quantity in shipment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>blueberry</td>\n      <td>4</td>\n      <td>5</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>orange</td>\n      <td>6</td>\n      <td>4</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ice cream sundae</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "             flavor  stock  shipment  quantity in shipment\n0         blueberry      4         5                    12\n1            orange      6         4                    12\n2  ice cream sundae     12         0                     0"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}