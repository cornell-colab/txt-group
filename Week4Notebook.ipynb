{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Functions and Regular Expressions\n## Functions\nAs we write more code in Python, we may find that we perform many of the same operations more than once. Rather than write the same loops multiple times, __functions__ allow us to perform those same operations in a condensed fashion, provided the parameters are similar. We might think of __functions__ as being akin to the saying \"You can give a person fish and feed them for the day or teach them how to fish and feed them for a lifetime\"; while fishing will be different depending on where and how one fishes, there are some universal parameters to fishing: a body of water, a means of extracting a fish from the water, and the presence fish. If we know the parameters in Python, we can create functions that will let us repeat operations.\n\nToday, we're using four poems that will all need to be preprocessed identically. Creating functions to perform this preprocessing will guarantee uniform results."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###Spring Poems###\n\nWSM_Late_Spring = \"Coming into the high room again after years/after oceans and shadows of hills and the/sounds of lies/after losses and feet on stairs/after looking and mistakes and forgetting/turning there thinking to find/no one except those I knew/finally I saw you/sitting in white/already waiting/you of whom I had heard/with my own ears since the beginning/for whom more than once/I had opened the door/believing you were not far\"\nED_LXXXV = \"A light exists in Spring/Not present on the year/At any other period/When March is scarely here/A color stands abroad/On solitary hills/That silence cannot overtake,/But human nature feels./It waits upon the lawn;/It shows the furthest tree/Upon the furthest slope we know;It almost speaks to me./Then,as horizons step,/Or noons report away./Without the formula of sound,/It passes, and we stay:/A quality of loss/Affecting our content,/As trade has suddenly encroached/Upon a sacrament\"\n\n###Fall Poems###\nCS_Written_in_October = \"The Blasts of Autumn as they scatter round/The faded foilage of another year,/And muttering many a sad and solemn sound,/Drive the pale fragments over the stubble sere,/Are well attuned to my dejected mood;/(Ah! better far than airs that breathe of Spring!)/While the high rooks, that horsely clamouring/Seek in the black phalanx the half-leafless wood,/I rather hear, than that enraptured lay/Harmonious, and of Lover and Pleasure born,/ Which from the golden furze, or flowering thorn/Awakes the Shepherd in the ides of May;/Nature delights me most when she mourns,/For never more to me the Spring of Hope returns!\"\n\nJK_To_Autumn = \"Season of mists and mellow fruitfulness,/Close bosom-friend of the maturing sun;/Conspiring with him how to load and bless/With fruit the vines that round the thatch-eves run;/To bend with apples the moss'd cottage-trees,/And fill all fruit with ripeness to the core;/To swell the gourd, and plump the hazel shells;With a sweet kernel; or set budding more,/And still more, later flowers for the bees,/Until they think warm days will never cease,/For summer has o'erbrimm'd their clammy cells./Who hath not seen thee oft amid thy store?/Sometimes whoever seeks abroad may find/Thee sitting careless on a granary floor,/Thy hair soft-lifted by the winnowing wind;/Or on a half-reap'd furrow sound asleep,/Drows'd with the fume of poppies, while thy hook/Spares the next swath and all its twined flowers:/And sometimes like a gleaner thou dost keep/Steady they laden head across a brook;/Or by a cyder-press, with patient look,/Thou watchest the last oozings hours by hours./Where are the songs of spring? Ay, Where are they?/ Think not of them, thou has thy mustic too,/While barred clouds bloom the soft-dying day,/And touch the stubble-plains with rosy hue;/ Then in a wailful choir the small gnats mourn/Among the river sallows, bourn aloft/ Or sinking as the light wind lives or dies;/And full-grown lambs loud bleat from hilly bourn;/Hedge-crickets sing; and now with treble soft/The red-breast whistles from a garden-croft;/And gathering swallows twitter in the skies.\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As you can see, each line of the poem is delimited by a slash. Each poem is currently a single string and we'll want to divide it by line number and then by individual word.\n\nFor the first step, we would typically use Python's .split() function. Since all of these poems are delimited by the same character, however, we're going to soup up the .split() function into a more useful, purpose-driven function."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def poem_splitter(poem):\n\treturn(poem.split('/'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To define a function in Python, we first type in def, followed by a name for the function. After the name, we include the parameters for what the function will accept. For example, the function defined as wash_clothing may have the parameter (quarters) or a more elaborate version may have several parameters, such as (quarters, detergent, dirty_laundry,existing_supply_of_clean_clothing). Here, we accept (poem), which is really the same as just accepting a single string. Choosing appropriately named variables, however, will help others look at and understand the code.\n\nAfter we've defined our parameters, we need to determine what we want to do with that information. Since I want to split the poem (a string) into separate lines (a list), I'm having python return a list where the poem is split by the '/' character. Let's see what this will give us."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "wsm_split = poem_splitter(WSM_Late_Spring)\nfor line in wsm_split:\n    print(line)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Looks like a poem alright! Use the poem_splitter function here to turn the other three poems into split versions."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ed_split =\ncs_split =\njk_split =",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "While these lines are excellent, today we're interested in the individual words that appear within the poem. As such, we need to take one more step in preprocessing our poems: tokenizing. \n\nWe've kind of tokenized in the past by using the split() function, namely by splitting at white space characters. Today, however, we're going to gently introduce you to __regular expressions__. Regular Expressions are a tool that allow you to find match and find character strings based on far more sophisticated techniques than seeing if one string equals the other. Notably __regular expressions__ allow you to include wild card characters and give directions about the positionality of a match based on others. You might find opening up regex101.com in an alternate window helpful. Let's try this out."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nsecret_message = \"t$%11x349t;]g*r21o?>u<-p\"\nwp = re.compile(\"[a-z]\")\nprint(''.join(wp.findall(secret_message)))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The code above uses a regular expression to find all of the characters between lowercase a and z in a string, joining them to reveal the secret message. This is only the tip of the iceberg when it comes to regular expression, but today we'll be using them to delimit word tokens."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def tokenizer(poem_split):\n\tword_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")\n\ttagged_poem = []\n\tfor line in range(len(poem_split)):\n\t\tt = poem_split[line].rstrip()\n\t\tword = word_pattern.findall(t)\n\t\tvital_info = [word, line]\n\t\ttagged_poem.append(vital_info)\n\treturn(tagged_poem)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's break down the code above. First, the tokenizer function takes in the split poem as a parameter. The second line introduces a word pattern that counts words surrounded by whitespace (including those that are hyphenated or feature an apostrophe) as a single word token. Next, we create an empty list where we'll create our tagged poem.\n\nA for-loop follows. For every line in the split poem, we clean away excess whitespace and find word tokens based on our regular expression pattern. Those tokens are then joined in a list with the line number, helping us retain important metadata. The tagged_poem is returned as a result. Let's see how this looks on our split poems"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "wsm_tagged = tokenizer(wsm_split)\n#ed_tagged = tokenizer(ed_split)\n#cs_tagged = tokenizer(cs_split)\n#jk_tagged = tokenizer(jk_split)\n\nprint(wsm_tagged)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our poetry data is so tidy now! While this format may seem less readable to human eyes, it allows us to start doing some pretty interesting things regarding both textual analysis and literary criticism.\n\nOne of the hallmarks of narratology, a midcentury branch of English criticism, is finding out who the speaker of a poem is. Rather than attribute the voice to the poem's author, the speaker of the poem is typically a figure embedded within the world of the poem itself.\n\nBy identifying how and where pronouns appear in a poem, we can begin to make claims about how the poet's speaker articulates themself. Below is a function designed to help us find where pronouns appear in each poem."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pronoun_finder(tagged_poem):\n\tSing_First_Person = [\"I\", \"Mine\", \"My\", \"Me\"]\n\tSing_Second_Person = [\"You\", \"Your\", \"Thee\", \"Thy\", \"Thou\"]\n\tSing_Third_Person = [\"He\", \"She\", \"It\", \"His\", \"Her\", \"Its\", \"Who\", \"Whom\"]\n\tPlural_First_Person = [\"We\", \"Our\"]\n\tPlural_Second_Person = [\"You\", \"Your\"]\n\tPlural_Third_Person = [\"They\", \"Their\", \"Those\"]\n\tpronoun_terms = [Sing_First_Person, Sing_Second_Person, Sing_Third_Person, Plural_First_Person, Plural_Second_Person, Plural_Third_Person]\n\tfor category in pronoun_terms:\n\t\tfor word in category:\n\t\t\tword = word.lower()\n\t\t\tfor cell in tagged_poem:\n\t\t\t\tline = cell[0]\n\t\t\t\tfor token in line:\n\t\t\t\t\ttoken = token.lower()\n\t\t\t\t\tif token == word:\n\t\t\t\t\t\tprint(cell[1], token, line)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pronoun_finder(wsm_tagged)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "While the function itself takes lists of pronouns and searches for them within each line of the poem, we may have some issues with the results. For one, \"You\" provides some ambiguity regarding whether the poem is discussing a singular you or a group of them. Second, and this may be a feature, it splits the lines based on the term its looking for rather than show us which terms each line features. Still, let's see if this provides any insight into the poems."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pronoun_finder(wsm_tagged)\npronoun_finder(ed_tagged)\npronoun_finder(cs_tagged)\npronoun_finder(jk_tagged)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Working together, let's create two similar functions that will provide us information about where month names appear and also how many prepositions appear in each poem."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def month_finder(tagged_poem):\nMonth_Names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def prep_finder(tagged_poem): \n\tpreps = [\"about\", \"below\", \"excepting\", \"off\", \"toward\", \"above\", \"beneath\", \"for\", \"on\", \"under\", \"across\", \"beside\", \"besides\", \"from\", \"onto\", \"underneath\", \"after\", \"between\", \"in\", \"out\", \"until\", \"against\", \"beyond\", \"in front of\", \"outside\", \"up\", \"along\", \"but\", \"inside\", \"over\", \"upon\", \"among\", \"by\", \"in spite of\", \"past\", \"up to\", \"around\", \"concerning\", \"instead of\", \"regarding\", \"with\", \"at\", \"despite\", \"into\", \"since\", \"within\", \"because\", \"down\", \"like\", \"through\", \"without\", \"before\", \"during\", \"near\", \"throughout\", \"with\", \"behind\", \"except\", \"of\", \"to\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Challenge ##\nUsing regular expressions, develop a function that will search for verbs. One approach is to search for words after nouns that feature \"ing\", \"ed\", \"s\" or other typical verb endings; using the preposition finder should help you find some nouns.\n\n*Note* This challenge is extremely difficult and it's unlikely you'll have complete accuracy finding verbs unless you import an NLP package. Still, it's worth testing which approaches garner the best results."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}